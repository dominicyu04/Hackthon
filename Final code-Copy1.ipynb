{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, GlobalMaxPooling1D, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Additional time and efforts are needed to collect enough data to feed in to the model\n",
    "(X_train,X_test),(y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 5000 \n",
    "embed_size  = 32\n",
    "max_len=2000\n",
    "trunc_type=\"post\"\n",
    "ovv_tok=\"<OVV>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = Tokenizer(num_words=vocabulary_size,oov_token=ovv_tok)\n",
    "tok.fit_on_texts(X_train)\n",
    "X_train = tok.texts_to_sequences(X_train)\n",
    "X_test  = tok.texts_to_sequences(X_test)\n",
    "X_train = pad_sequences(X_train,maxlen=max_len,truncating=trunc_type,padding=\"post\")\n",
    "X_test = pad_sequences(X_test,maxlen=max_len,truncating=trunc_type,padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary_size,embed_size,input_length = max_len))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))          \n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model.add(GlobalMaxPooling1D())                                        \n",
    "model.add(Dense(256, activation='relu'))                                             \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu')) \n",
    "model.add(Dropout(0.2))                                                \n",
    "model.add(Dense(64, activation='relu')) \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(5, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy']             \n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train,batch_size=256,validation_data=(X_test,y_test),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
